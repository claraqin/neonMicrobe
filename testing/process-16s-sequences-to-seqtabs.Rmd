---
title: "Process 16S Sequences into Sequence Tables Only"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{process-its-sequences}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_knit$set(
  root.dir = rprojroot::find_rstudio_root_file() # Update as necessary. Should refer to the absolute filepath of the project root directory (e.g. .../neonSoilMicrobeProcessing)
)
```


**This version of the Process 16S Sequences vignette processes the raw NEON 16S sequence data into sequence tables only, and does not take the additional steps to join the sequence tables together or to assign taxonomy. Therefore, this version of the vignette forgoes these high-memory, long-running processes for users with large datasets or with limited computing resources.**

**Note:** If you are using this vignette as a reference, rather than running it as an RMarkdown script, be aware that you will need to manually set the working directory to the project root directory, e.g. `setwd(".../neonSoilMicrobeProcessing")`.

# Dependencies

To begin, ensure that you have installed all dependencies.

From BiocManager:

```{r eval=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")
BiocManager::install("ShortRead")
BiocManager::install("Biostrings")
BiocManager::install("dada2")
```

From CRAN:
```{r eval=FALSE}
install.packages(dplyr)
```

Load libraries

```{r message=FALSE}
library(ShortRead)
library(Biostrings)
library(dada2)
library(dplyr)
```

In addition, source files associated with this package:

```{r}
source("./R/utils.R")
source("./code/params.R")
```

# Setup variables

Get filepath names:

```{r}
if(is.null(PRESET_OUTDIR_SEQUENCE) | PRESET_OUTDIR_SEQUENCE == "") {
  PATH_16S <- file.path(PRESET_OUTDIR, "raw_sequence", "16S")
} else {
  PATH_16S <- file.path(PRESET_OUTDIR, PRESET_OUTDIR_SEQUENCE, "16S")
}
PATH_RAW <- file.path(PATH_16S, "0_raw")
PATH_TRIMMED <- file.path(PATH_16S, "1_trimmed")
PATH_FILTERED <- file.path(PATH_16S, "2_filtered")
PATH_SEQTABS <- file.path(PATH_16S, "3_seqtabs")
PATH_TRACK <- file.path(PATH_16S, "track_reads")
```

Get all run IDs so you can group by them:

```{r}
unique_runs <- unique(unlist(
  regmatches(list.files(PATH_RAW), gregexpr("^run[A-Za-z0-9]*", list.files(PATH_RAW)))
))
```

If SMALL_SUBSET == TRUE, run only the first runID. This can be useful for debugging. (SMALL_SUBSET is a parameter that can be found within params.R.)

```{r}
if (SMALL_SUBSET) {
  loop_length <- 1
} else {
  loop_length <- length(unique_runs)
}
```

# Process reads

We use DADA2 to process reads one sequencing run at a time.

```{r}
# all.seqtabs <- list() # Removed for testing version
t1 <- Sys.time()
ti <- c()
first <- TRUE
for (i in 1:loop_length) {
  runID <- unique_runs[i]
  message(paste0("Began processing ", runID, " at ", Sys.time()))

  # Forward and reverse fastq filenames have format: SAMPLENAME_R1.fastq and SAMPLENAME_R2.fastq
  fnFs <- sort(list.files(PATH_RAW, pattern=paste0(runID, ".*_R1.fastq"), full.names = TRUE))
  fnRs <- sort(list.files(PATH_RAW, pattern=paste0(runID, ".*_R2.fastq"), full.names = TRUE))

  # If SMALL_SUBSET == TRUE,
  # keep only the first two forward-reverse pairs of sequence files
  if(SMALL_SUBSET){
    if(length(fnFs > 2)) fnFs <- fnFs[1:2]
    if(length(fnRs > 2)) fnRs <- fnRs[1:2]
  }

  # Remove any files that only have forward or reverse reads
  matched_fn <- remove_unmatched_files(fnFs, fnRs)
  fnFs <- matched_fn[[1]]
  fnRs <- matched_fn[[2]]
  
  fn_base <- basename(c(fnFs, fnRs))

  # Trim reads based on the primer lengths supplied in params.r
  trim_trackReads <- trimPrimers16S(fn_base, PATH_RAW, PATH_TRIMMED, "CCTACGGGNBGCASCAG", "GACTACNVGGGTATCTAATCC")

  # Filter reads based on the settings in params.r
  filter_trackReads <- qualityFilter16S(fn_base, PATH_TRIMMED, PATH_FILTERED, MULTITHREAD, maxEE = c(MAX_EE_FWD, MAX_EE_REV), truncLen_manual = NULL) # truncation lengths will be determined automatically using get_truncation_length()

  # Now create sequence table for run
  seqtab.list <- runDada16S(fn_base, PATH_FILTERED, MULTITHREAD, VERBOSE)

  # Create output tracking file
  track <- Reduce(
    function(x, y, ...) transform(merge(x, y, by=0, all = TRUE, ...), row.names=Row.names, Row.names=NULL),
    list(trim_trackReads, 
         filter_trackReads[,2,drop=FALSE], 
         seqtab.list$track)
  )
  names(track)[3] <- "filtered"
  track[is.na(track)] <- 0

  # Append sequence table to output list
  # all.seqtabs[[runID]] <- seqtab.list$seqtab.nochim # Removed for testing version

  # Save tracking table (which tracks no. of reads remaining at each stage) and sequence table
  if(SMALL_SUBSET) {
    write.csv(track, file.path(PATH_TRACK, paste0("track_reads_",runID,"_SMALLSUBSET.csv")))
    saveRDS(seqtab.list$seqtab.nochim, file.path(PATH_SEQTABS, paste0("NEON_16S_seqtab_nochim_", runID, "_SMALLSUBSET.rds")))
  } else {
    write.csv(track, file.path(PATH_TRACK, paste0("track_reads_",runID,".csv")))
    saveRDS(seqtab.list$seqtab.nochim, file.path(PATH_SEQTABS, paste0("NEON_16S_seqtab_nochim_", runID, ".rds")))
  }
  message(paste0("Finished processing reads in ", runID, " at ", Sys.time()))
  message(paste0("Sequencing run-specific sequence tables can be found in ", PATH_SEQTABS))
}
```

# All code below is NOT run in this version of the vignette

Merge the sequence tables from all runs

```{r eval=FALSE}
if(length(all.seqtabs) == 1) {
  seqtab_joined <- all.seqtabs[[1]]
} else {
  seqtab_joined <- mergeSequenceTables(tables = all.seqtabs)
}
```

## Assign taxonomy using the Silva reference database

```{r eval=FALSE}
tax <- assignTaxonomy(seqtab_joined, SILVA_REF_PATH, multithread = MULTITHREAD, verbose = VERBOSE)
```

## Save processed data to file

```{r eval=FALSE}
# Save OTU table and taxonomic table as RDS files
# to hand off to dada2_to_phyloseq.R
saveRDS(seqtab_joined, "./data/NEON_16S_seqtab_nochim.Rds")
saveRDS(tax, "./data/NEON_16S_tax.Rds")
```


