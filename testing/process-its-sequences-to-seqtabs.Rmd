---
title: "Process ITS Sequences into Sequence Tables Only"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{process-its-sequences}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_knit$set(
  root.dir = rprojroot::find_rstudio_root_file() # Update as necessary. Should refer to the absolute filepath of the project root directory (e.g. .../neonSoilMicrobeProcessing)
)
```

This vignette demonstrates how to use the functions and parameters in this package to process the raw NEON ITS sequence data into ASV tables. This vignette processes only the forward ITS reads, following recommendations by Pauvert et al. (2019).

**This version of the Process ITS Sequences vignette processes the raw NEON ITS sequence data into sequence tables only, and does not take the additional steps to join the sequence tables together or to assign taxonomy. Therefore, this version of the vignette forgoes these high-memory, long-running processes for users with large datasets or with limited computing resources.**

**Note:** If you are using this vignette as a reference, rather than running it as an RMarkdown script, be aware that you will need to manually set the working directory to the project root directory, e.g. `setwd(".../neonSoilMicrobeProcessing")`.

# Dependencies

To begin, ensure that you have installed all dependencies.

From BiocManager:

```{r eval=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")
BiocManager::install("ShortRead")
BiocManager::install("Biostrings")
BiocManager::install("dada2")
```

From CRAN:
```{r eval=FALSE}
install.packages(dplyr)
```

Load libraries

```{r message=FALSE}
library(ShortRead)
library(Biostrings)
library(dada2)
library(dplyr)
```

In addition, source files associated with this package:

```{r}
source("./R/utils.R")
source("./code/params.R")
```

# Setup variables

Get filepath names:

```{r}
if(is.null(PRESET_OUTDIR_SEQUENCE) | PRESET_OUTDIR_SEQUENCE == "") {
  PATH_ITS <- file.path(PRESET_OUTDIR, "raw_sequence", "ITS")
} else {
  PATH_ITS <- file.path(PRESET_OUTDIR, PRESET_OUTDIR_SEQUENCE, "ITS")
}
PATH_RAW <- file.path(PATH_ITS, "0_raw")
PATH_FILTN <- file.path(PATH_ITS, "1_filtN")
PATH_TRIMMED <- file.path(PATH_ITS, "2_trimmed")
PATH_FILTERED <- file.path(PATH_ITS, "3_filtered")
PATH_SEQTABS <- file.path(PATH_ITS, "4_seqtabs")
PATH_TRACK <- file.path(PATH_ITS, "track_reads")
```

Get all run IDs so you can group by them:

```{r}
unique_runs <- unique(unlist(
  regmatches(list.files(PATH_RAW), gregexpr("^run[A-Za-z0-9]*", list.files(PATH_RAW)))
))
```

If SMALL_SUBSET == TRUE, run only the first runID. This can be useful for debugging. (SMALL_SUBSET is a parameter that can be found within params.R.)

```{r}
if (SMALL_SUBSET) {
  loop_length <- 1
} else {
  loop_length <- length(unique_runs)
}
```

# Process reads

We use DADA2 to process reads one sequencing run at a time.

```{r}
# all.seqtabs <- list() # Removed for testing version
t1 <- Sys.time()
ti <- c()
for (i in 1:loop_length) {
  runID <- unique_runs[i]
  message(paste0("Began processing ", runID, " at ", Sys.time()))

  # Forward and reverse fastq filenames have format: SAMPLENAME_R1.fastq
  fnFs <- sort(list.files(PATH_RAW, pattern=paste0(runID, ".*_R1.fastq"), full.names = TRUE))

  # If SMALL_SUBSET == TRUE,
  # keep only the first two forward-reverse pairs of sequence files
  if(SMALL_SUBSET){
    if(length(fnFs > 2)) fnFs <- fnFs[1:2]
  }
  
  fn_base <- basename(fnFs)
  
  # "Pre-filter" the sequences just to remove those with Ns, but perform no other filtering
  prefilter_trackReads <- qualityFilterITS(fn_base, PATH_RAW, PATH_FILTN, maxN = 0)

  # Trim reads based on the primer lengths supplied in params.r
  trimPrimersITS(fn_base, PATH_FILTN, paste0(PATH_TRIMMED,"_mid"), "CTTGGTCATTTAGAGGAAGTAA", "GCTGCGTTCTTCATCGATGC")
  trimPrimersITS(fn_base, paste0(PATH_TRIMMED,"_mid"), PATH_TRIMMED, "GCTGCGTTCTTCATCGATGC", "CTTGGTCATTTAGAGGAAGTAA")
  #unlink(paste0(PATH_TRIMMED,"_mid"), recursive=TRUE)
  # Note: We use cutadapt twice because some NEON ITS sequencing runs are in mixed orientation -- that is, some R1 sequences are actually reverse-oriented, and some R2 sequences are actually forward-oriented.

  # Filter reads based on the settings in params.r
  filter_trackReads <- qualityFilterITS(fn_base, PATH_TRIMMED, PATH_FILTERED, MULTITHREAD, maxEE=8)

  # Now create sequence table for run
  seqtab.list <- runDadaITS(fn_base, PATH_FILTERED, MULTITHREAD, VERBOSE)

  # Create output tracking file
  track <- Reduce(
    function(x, y, ...) transform(merge(x, y, by=0, all = TRUE, ...), row.names=Row.names, Row.names=NULL),
    list(prefilter_trackReads, 
         filter_trackReads, 
         seqtab.list$track)
  )
  names(track)[1:4] <- c("reads.in", "prefiltered", "trimmed", "filtered")
  track[is.na(track)] <- 0
  
  # Append sequence table to output list
  # all.seqtabs[[runID]] <- seqtab.list$seqtab.nochim # Removed for testing version

  # Save tracking table (which tracks no. of reads remaining at each stage) and sequence table
  if(SMALL_SUBSET) {
    write.csv(track, file.path(PATH_TRACK, paste0("track_reads_",runID,"_SMALLSUBSET.csv")))
    saveRDS(seqtab.list$seqtab.nochim, file.path(PATH_SEQTABS, paste0("NEON_ITS_seqtab_nochim_", runID, "_SMALLSUBSET.rds")))
    saveRDS(seqtab.list$seqtab, file.path(PATH_SEQTABS, paste0("NEON_ITS_seqtab_", runID, "_SMALLSUBSET.rds")))
  } else {
    write.csv(track, file.path(PATH_TRACK, paste0("track_reads_",runID,".csv")))
    saveRDS(seqtab.list$seqtab.nochim, file.path(PATH_SEQTABS, paste0("NEON_ITS_seqtab_nochim_", runID, ".rds")))
    saveRDS(seqtab.list$seqtab, file.path(PATH_SEQTABS, paste0("NEON_ITS_seqtab_", runID, ".rds")))
  }
  message(paste0("Finished processing reads in ", runID, " at ", Sys.time()))
  message(paste0("Sequencing run-specific sequence tables can be found in ", PATH_SEQTABS))
}
```

# All code below is NOT run in this version of the vignette

Merge the sequence tables from all runs:

```{r eval=FALSE}
if(length(all.seqtabs) == 1) {
  seqtab_joined <- all.seqtabs[[1]]
} else {
  seqtab_joined <- mergeSequenceTables(tables = all.seqtabs)
}
```


## Assign taxonomy using the UNITE reference database

```{r eval=FALSE}
tax <- assignTaxonomy(seqtab_joined, UNITE_REF_PATH, multithread = MULTITHREAD, verbose = VERBOSE)
```

## Save processed data to file

```{r eval=FALSE}
# saveRDS(seqtab_joined, "./data/NEON_ITS_seqtab_nochim.Rds")
saveRDS(seqtab_joined, "./data/NEON_ITS_seqtab.Rds")
```

```{r eval=FALSE}
saveRDS(tax, "./data/NEON_ITS_tax.Rds")
```

The ASV table and taxonomic table will be joined into a phyloseq object, and will also be joined with environmental data, in the next vignette.


