---
title: "Plot DADA2 sensitivity tests"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/raid/users/claraqin/zhulab/NEON_soil_microbe_processing")
```

The purpose of this R Markdown document is to demonstrate the effects of various DADA2 quality filtering parameter combinations on the outputs of the DADA2 pipeline, and ultimately, on the ecological inference. Specifically, this script asks the following:

* What are the effects of quality filtering parameters on volume of remaining reads?
* What are the effects of quality filtering parameters on merging success?
* What are the effects of quality filtering parameters on taxonomic assignment?
* What are the effects of quality filtering parameters on alpha and beta diversity metrics?

The parameters that we vary to observe their downstream effects include the following:

* `truncQ`: Each read will be truncated at the first base pair for which the quality score is equal or less than `truncQ`; default 2.
* `maxEE`: After truncation, reads with higher than `maxEE` expected errors will be discarded. Expected errors are calculated from the nominal definition of the quality score: EE = sum(10^(-Q/10)).

Because we are interested in variation in these benchmark metrics across different parameter sets, we refer to this analysis as a **sensitivity analysis**.

This script only produces the plots and tables associated with the sensitivity analysis. The statistical computation takes place in a partner script, `test_dada2_params.R`, which is available to collaborators in the NEON Soil Microbe Methods project [here](https://github.com/claraqin/NEON_soil_microbe_processing/blob/master/code/test_dada2_params.R). This script reads in the outputs of `test_dada2_params.R` via the `readRDS` function. See below for instructions on accessing the associated the .Rds files.


# Load data, libraries, and parameters

The .Rds files listed below are created by `test_dada2_params.R`. If you have access to `test_dada2_params.R` you can run it yourself. However, you can save yourself (substantial) processing time by downloading them directly from this link: https://drive.google.com/file/d/1CBeMuGqRiNWxY1sgpIJmBXfZ6P5wRr3Y/view?usp=sharing. Once downloaded, move the contents to the `./data` subdirectory.

```{r}
runIDs <- c("B69PP", "C25G9")

cutFs <- readRDS("./data/sensitivity_cutFs.Rds")
cutRs <- readRDS("./data/sensitivity_cutRs.Rds")
params <- readRDS("./data/sensitivity_params.Rds")
out_list <- readRDS("./data/sensitivity_filterAndTrim_out_list.Rds")
prop_Fs_mapped_to_asv <- readRDS("./data/sensitivity_prop_Fs_mapped.Rds")
# dadaFs_list <- readRDS("./data/sensitivity_dadaFs_list.Rds")
# dadaRs_list <- readRDS("./data/sensitivity_dadaRs_list.Rds")
seqtabs <- readRDS("./data/sensitivity_seqtabs_list.Rds")
taxas <- readRDS("./data/sensitivity_taxas.Rds")
n_merged <- readRDS("./data/sensitivity_n_merged.Rds")
prop_merged <- readRDS("./data/sensitivity_prop_merged.Rds")
taxa_joined <- readRDS("./data/sensitivity_taxa_joined.Rds")

param_sets <- apply(params, 1, function(x) paste(c(rbind(c("maxEE.F", "maxEE.R", "truncQ"), x)), collapse="_"))

source("./code/params.R")

suppressMessages({
  library(dada2)
  library(ShortRead)
  library(Biostrings)
  library(tibble)
  library(dplyr)
  library(vegan)
  library(phyloseq)
  library(ggplot2)
  library(stringr)
})

theme_set(theme_bw())
```


# Plot outputs of filterAndTrim

Number of reads remaining after filterAndTrim:

```{r}
library(ggplot2)

filterAndTrim_out <- 
  data.frame(
    runID = rep(rep(runIDs, each=50), 16),
    maxEE = rep(params[,1], each=100),
    truncQ = rep(params[,3], each=100),
    n.in = unlist(lapply(out_list, function(x) x[,"reads.in"])),
    n.out = unlist(lapply(out_list, function(x) x[,"reads.out"])),
    prop.out = unlist(lapply(out_list, function(x) x[,"prop.out"]))
)

filterAndTrim_out %>%
  ggplot(aes(x=factor(maxEE), y=prop.out, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.)
```

`truncQ=8` seems to be the best option. Unclear what `maxEE` value is best, because values that are too high could fail to remove low-quality reads.

Is there a relationship between number of input reads and proportion of reads remaining?

```{r}
filterAndTrim_out %>%
  ggplot(aes(x=n.in, y=prop.out, col=runID)) +
  geom_point(alpha=0.5) + 
  geom_smooth(method='lm', formula = y~x)
```

Yes, there is. That means that the samples with more reads are also the samples with the higher quality reads.

Still, there is no guarantee that any of these output reads are of sufficient quality to be assigned taxonomy, or that they will merge.

# Plot outputs of DADA algorithm

### Note:

**This section and all subsequent sections should are re-run later in this report so that the DADA error rate estimation and denoising algorithm occurs separately for each sequencing run. Here, the process handles both run B69PP and run C25G9 together; these should probably be processed independently of each other. That being said, ANOVA shows that whether these runs are processed together or separately has no impact on the resulting alpha- and beta-diversity estimates.**

```{r}
# prop_Fs_mapped_to_asv <- lapply(dadaFs_list, function(x) lapply(x, function(y) mean(!is.na(y$map))))

paramset_index <- unlist(lapply(seq_along(prop_merged), function(i) { rep(i, length(prop_merged[[i]]))}))
dada_out <-
  data.frame(
    runID = unlist(lapply(
      prop_merged, function(x) str_extract(names(x), paste0("(", runIDs, ")", collapse="|"))
      )),
    maxEE = params[paramset_index, 1],
    truncQ = params[paramset_index, 3],
    prop.Fs.mapped = unlist(prop_Fs_mapped_to_asv),
    prop.merged = unlist(prop_merged)
  )
```

Plot the proportion of forward reads that were assigned to an ASV in the DADA denoising algorithm (out of the reads which have been filtered and dereplicated):

```{r}
dada_out %>%
  ggplot(aes(x=factor(maxEE), y=prop.Fs.mapped, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_prop_mapped
p_prop_mapped
```

Plot the proportion of unique ASVs that successfully merged (out of the unique ASVs that have been denoised):

```{r}
dada_out %>%
  ggplot(aes(x=factor(maxEE), y=prop.merged, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_prop_merged
p_prop_merged
```

From the results so far, we know that higher values of `truncQ` and `maxEE` allow *more* reads to pass `filterAndTrim()`, but *fewer* reads to make it through the next steps. Can we integrate the outputs of all these steps to see the rate of **merged ASVs per input read**?

Plot rate of merged ASVs per pre-filter read:

```{r}
sample_ind <- lapply(n_merged, function(x) match(names(x), sub("_R(1|2).fastq$", "", basename(cutFs))))
dada_out$merged.variants.per.read <- unlist(lapply(seq_along(n_merged), function(i) n_merged[[i]]/out_list[[i]][sample_ind[[i]],"reads.in"]))

dada_out %>%
  ggplot(aes(x=factor(maxEE), y=merged.variants.per.read, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_rate_merged
p_rate_merged
```

**Question:** It has previously been stated that this metric may not be the best to use, because it is also a function of the variation between reads (more variation --> more unique sequence variants identified by the DADA algorithm). However, since each processing run (each parameter set) starts with the same input data, isn't the variation between reads held constant across processing runs?

Use ANOVA to confirm effects of parameters on "rate of merged ASVs per pre-filter read":

```{r}
rate_merged_aov <- aov(merged.variants.per.read ~ maxEE*runID + truncQ*runID, data=dada_out)
par(mfrow=c(2,2))
plot(rate_merged_aov)
```

```{r}
summary(rate_merged_aov)
```

**`maxEE` and `truncQ` both affect the number of reads in the resulting ASV table.** The effect of `truncQ` varies across sequencing runs.

# Plot effects on taxonomic assignment

```{r}
physeqs <- list() # Create a list of physeq objects
prop_spp_classification <- list() # Proportion of unique ASVs with species-level classification
abund_spp_classification <- list() # Total abundance of ASVs with species-level classifications
abundweight_prop_spp_classification <- list() # Proportion-by-abundance of ASVs with species-level classification
n_spp_classification <- list() # Number of unique ASVs with species-level classification
for(i in 1:length(seqtabs)) {
  physeqs[[i]] <- phyloseq(otu_table(seqtabs[[i]],taxa_are_rows=FALSE), tax_table(taxas[[i]]))
  prop_spp_classification[[i]] <- mean(!is.na(tax_table(physeqs[[i]])[,"Species"]))
  abund_spp_classification[[i]] <- sum(otu_table(subset_taxa(physeqs[[i]], !is.na(Species))))
  abundweight_prop_spp_classification[[i]] <- abund_spp_classification[[i]] / sum(otu_table(physeqs[[i]]))
  n_spp_classification[[i]] <- sum(!is.na(tax_table(physeqs[[i]])[,"Species"]))
}

assigntax_out <- 
  data.frame(
    maxEE = params[,1],
    truncQ = params[,3],
    prop.spp.classification = unlist(prop_spp_classification),
    abund.weight.prop.spp.classification = unlist(abundweight_prop_spp_classification),
    n.spp.classification = unlist(n_spp_classification)
  )
```

Plot the proportion of unique taxonomic assignments that went down to the species level:

```{r, fig.height=4}
assigntax_out %>%
  ggplot(aes(x=factor(maxEE), y=prop.spp.classification, fill=factor(truncQ))) +
  geom_bar(stat="identity", position=position_dodge())
```

Plot the abundance-weighted proportion, and the number, of unique taxonomic assignments that went down to the species level.

```{r fig.height=3, fig.width=7}
gridExtra::grid.arrange(
  assigntax_out %>%
  ggplot(aes(x=factor(maxEE), y=abund.weight.prop.spp.classification, fill=factor(truncQ))) +
  geom_bar(stat="identity", position=position_dodge()),
  assigntax_out %>%
  ggplot(aes(x=factor(maxEE), y=n.spp.classification, fill=factor(truncQ))) +
  geom_bar(stat="identity", position=position_dodge()),
  nrow=1
)
```

**Question:** It is not clear which benchmark metric is the most appropriate for evaluating the impact of quality filtering parameters on taxonomic assignment. 

Suppose for now that we are most interested in the number of unique species-level classifications to come out of a set of samples. Then we can conclude that **higher values of `truncQ` result in lower taxonomic assignment rates, while higher values of `maxEE` result in higher taxonomic assignment rates.**

# Plot effects on alpha-diversity estimates

Begin by rarefying all samples to a common sequencing depth. We can start with a generous minimum of 1000 sequences.

```{r message=FALSE}
physeqs_rare <- list()
set.seed(1001010100)
for(i in 1:length(physeqs)) {
  physeqs_rare[[i]] <- rarefy_even_depth(physeqs[[i]], sample.size = 1000)
}
```


```{r}
obsrich_list <- list()
shannon_list <- list()
for(i in 1:length(physeqs_rare)) {
  div <- suppressWarnings(
    estimate_richness(physeqs_rare[[i]], measures=c("Observed","Shannon"))
  )
  obsrich_list[[i]] <- div[,"Observed"]
  shannon_list[[i]] <- div[,"Shannon"]
}

paramset_index <- unlist(lapply(seq_along(obsrich_list), function(i) { rep(i, length(obsrich_list[[i]]))}))
diversity_out <- 
  data.frame(
    runID = unlist(lapply(
      physeqs_rare, function(x) str_extract(sample_names(x), paste0("(", runIDs, ")", collapse="|"))
      )),
    maxEE = params[paramset_index, 1],
    truncQ = params[paramset_index, 3],
    obs.richness = unlist(obsrich_list),
    shannon.div = unlist(shannon_list)
  )
```

Plot observed richness: 

(Note: DADA2 does not allow singletons, so this measure should not be used directly for ecological inference.)

```{r}
diversity_out %>%
  ggplot(aes(x=factor(maxEE), y=obs.richness, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_obsrich
p_obsrich
```

Plot Shannon diversity:

```{r}
diversity_out %>%
  ggplot(aes(x=factor(maxEE), y=shannon.div, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_shannon
p_shannon
```

It seems like the parameters make little difference in the diversity estimates. For observed richness, though, low values of `truncQ` result in slightly higher estimates.

### Confirm results with ANOVA

First, test observed richness:

```{r}
par(mfrow=c(2,2))
obsrich_aov <- aov(obs.richness ~ truncQ + maxEE + runID + runID:truncQ + runID:maxEE, data=diversity_out)
plot(obsrich_aov)
```

Normality assumption approximately holds.

Check summary:

```{r}
par(mfrow=c(1,1))
summary(obsrich_aov)
```

Now, test Shannon diversity:

```{r}
shannon_aov <- aov(shannon.div ~ truncQ + maxEE + runID + runID:truncQ + runID:maxEE, data=diversity_out)
par(mfrow=c(2,2))
plot(shannon_aov)
```

Normality assumption approximately holds.

Check summary:

```{r}
par(mfrow=c(1,1))
summary(shannon_aov)
```

It seems like the significance of the `truncQ` coefficient may be due to the high leverage of the `truncQ = 16` simulations. Suppose we only varied `truncQ` within 2-8.

```{r}
diversity_out_2_8 <- diversity_out[which(diversity_out$truncQ <= 8),]
obsrich_aov_2_8 <- aov(obs.richness ~ truncQ + maxEE + runID + runID:truncQ + runID:maxEE, data=diversity_out_2_8)
shannon_aov_2_8 <- aov(shannon.div ~ truncQ + maxEE + runID + runID:truncQ + runID:maxEE, data=diversity_out_2_8)
```

```{r}
summary(obsrich_aov_2_8)
```

```{r}
summary(shannon_aov_2_8)
```

If we only consider values of `truncQ` between 2 and 8, then the effect of `truncQ` becomes insignificant for Shannon diversity. They are still significant for observed richness, but less so.

In conclusion, **`truncQ` has a small but significant effect on observed richness, with higher estimates at lower values of `truncQ`.** But `truncQ` does not affect Shannon diversity within the range of `2 < truncQ < 8`. `maxEE` has no effect on alpha-diversity estimates.


# Plot effects on beta-diversity

First, create phyloseq object to combine sequence tables across all parameter sets:

```{r}
# First rename each seqtab to reflect the params that created it.
# Then combine all seqtabs into ONE physeq
seqtabs_renamed <- seqtabs
for(i in 1:length(seqtabs_renamed)) {
  rownames(seqtabs_renamed[[i]]) <- paste0(param_sets[i], "_", rownames(seqtabs[[i]]))
}
seqtab_joined <- mergeSequenceTables(tables=seqtabs_renamed)
rm(seqtabs_renamed)

# Sample data (parameters)
paramset_index <- unlist(lapply(seq_along(seqtabs), function(i) { rep(i, nrow(seqtabs[[i]]))}))
sampledata <- as.data.frame(params[paramset_index,]) %>%
  mutate(sample = unname(unlist(lapply(seqtabs, rownames))))
rownames(sampledata) <- rownames(seqtab_joined)

# Taxa
# taxa_joined <- assignTaxonomy(seqtab_joined, unite.ref, multithread = MULTITHREAD, tryRC = TRUE)
taxa_joined <- readRDS("./data/sensitivity_taxa_joined.Rds")

# Combine elements into physeq
physeq_joined <- phyloseq(otu_table(seqtab_joined,taxa_are_rows=FALSE),
                          sample_data(sampledata),
                          tax_table(taxa_joined))

# Remove samples with zero total counts
physeq_joined_nonzero <- prune_samples(sample_sums(physeq_joined) > 0, physeq_joined)
```

Plot ordination:

```{r}
# ordination <- ordinate(physeq_joined_nonzero, "NMDS", "bray", k=2)
# saveRDS(ordination, "./data/sensitivity_ordination.Rds")
ordination <- readRDS("./data/sensitivity_ordination.Rds")
plot_ordination(physeq_joined_nonzero, ordination, type="samples",
                col="truncQ")
```

The far-right outliers come from two samples (runB69PP_BMI_Plate4WellH3_ITS and runB69PP_BMI_Plate4WellH1_ITS), but they are also notable in that they have `truncQ = 16`. Therefore, this plot demonstrates that `truncQ < 16` is necessary to avoid extreme outliers.

Check: Are there other signs that these samples would have been outliers? For instance, do they have unusually low sequencing depth?

```{r, fig.width=5, fig.height=3}
hist(sample_sums(physeq_joined_nonzero))
```

```{r, fig.width=5, fig.height=3}
outliers <- c("runB69PP_BMI_Plate4WellH3_ITS", "runB69PP_BMI_Plate4WellH1_ITS")
physeq_joined_beta_outliers <- subset_samples(physeq_joined_nonzero, get_variable(physeq_joined_nonzero, "sample") %in% outliers)
hist(sample_sums(physeq_joined_beta_outliers))
```

Beta-diversity outliers have extremely low sequencing depth! So yes they would have been removed in the pre-analysis stage anyway. (See below for re-analysis with low-depth samples removed.)

Zoom in on plot around (0,0):

```{r}
plot_ordination(physeq_joined_nonzero, ordination, type="samples",
                col="truncQ") +
  coord_cartesian(xlim=c(-0.096, -0.09), ylim=c(-0.002, 0.001))
```

Within the main point cloud, there is no apparent effect of `truncQ` on inferred community composition.

Color some samples to see how closely they cluster:

```{r}
select_samples <- c("runB69PP_BMI_Plate13WellA8_ITS", "runB69PP_BMI_Plate13WellC11_ITS",
                    "runC25G9_BMI_Plate68WellC12_ITS", "runC25G9_BMI_Plate68WellE1_ITS")
select_sample_ind <- match(get_variable(physeq_joined_nonzero, "sample"), select_samples)
sample_data(physeq_joined_nonzero)[,"sample_select"] <- select_samples[select_sample_ind]

plot_ordination(physeq_joined_nonzero, ordination, type="samples",
                col="sample_select") +
  coord_cartesian(xlim=c(-0.096, -0.09), ylim=c(-0.002, 0.001))
```

It looks like samples don't necessarily form clusters that are distinguishable from the rest of the variation.

Confirm with PERMANOVA: How does dissimilarity between samples compare to dissimilarity between parameter sets for a given sample? (These can take several minutes to run, so the corresponding output is pasted below each code chunk.)

```{r eval=FALSE}
adonis(formula = ps_joined_dist ~ maxEE.F + truncQ + sample,
       data = as(sample_data(physeq_joined_nonzero), "data.frame"),
       permutations = 999) 
```

```
Permutation: free
Number of permutations: 999
Terms added sequentially (first to last)
            Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)    
maxEE.F      1      0.03  0.0298   1.036 0.00004  0.376    
truncQ       1      0.46  0.4570  15.890 0.00060  0.001 ***
sample      98    714.68  7.2926 253.541 0.94393  0.001 ***
Residuals 1459     41.97  0.0288         0.05543           
Total     1559    757.13                 1.00000           
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

Beta diversity varies much more between samples than within samples. We expect clustering by samples in NMDS plots.

Now, stratifying by sample (so that permutations only take place within samples):

```{r eval=FALSE}
ps_joined_dist <- vegdist(otu_table(physeq_joined_nonzero))
adonis(ps_joined_dist ~ maxEE.F + truncQ,
       data = as(sample_data(physeq_joined_nonzero), "data.frame"),
       strata = get_variable(physeq_joined_nonzero, "sample"),
       permutations=999)
```

```
Call:
adonis(formula = ps_joined_dist ~ maxEE.F + truncQ, data = as(sample_data(physeq_joined_nonzero),      "data.frame"), permutations = 999, strata = get_variable(physeq_joined_nonzero,      "sample")) 

Blocks:  strata 
Permutation: free
Number of permutations: 999

Terms added sequentially (first to last)

            Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)    
maxEE.F      1      0.03 0.02980 0.06132 0.00004  0.391    
truncQ       1      0.46 0.45704 0.94050 0.00060  0.001 ***
Residuals 1557    756.64 0.48596         0.99936           
Total     1559    757.13                 1.00000           
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

In conclusion, different parameter sets could lead to slightly different inferences about beta-diversity.

### Re-run beta-diversity analyses without outlier samples

The fact that all 8 extreme outliers had `truncQ = 16` suggests that the outliers may have inflated the importance of `truncQ` in affecting beta diversity. We can remove outliers by removing samples with very low sequencing depths. Let's remove all samples with sequencing depth below 1000, to be very lenient.

```{r}
mean(sample_sums(physeq_joined_nonzero) < 1000)
```

The minimum depth requirement removes ~28% of all samples. 

```{r}
physeq_joined_nonzero_mindepth <- subset_samples(physeq_joined_nonzero, sample_sums(physeq_joined_nonzero) >= 1000)
```

Ordinate:

```{r}
# ordination_mindepth <- ordinate(physeq_joined_nonzero_mindepth, "NMDS", "bray", k=2)
# saveRDS(ordination_mindepth, "./data/sensitivity_ordination_mindepth.Rds")
ordination_mindepth <- readRDS("./data/sensitivity_ordination_mindepth.Rds")
plot_ordination(physeq_joined_nonzero_mindepth, ordination_mindepth, type="samples",
                col="truncQ")
```

Effect of `truncQ` is not visible from NMDS.

Clustering by sample ID?

```{r}
plot_ordination(physeq_joined_nonzero_mindepth, ordination_mindepth, type="samples",
                col="sample_select")
```

Yes, the by-sample clustering is visible in an NMDS graph.

Now confirm effects of parameters on beta diversity by PERMANOVA:

```{r eval=FALSE}
ps_joined_mindepth_dist <- vegdist(otu_table(physeq_joined_nonzero_mindepth))
adonis(ps_joined_mindepth_dist ~ maxEE.F + truncQ,
       data = as(sample_data(physeq_joined_nonzero_mindepth), "data.frame"),
       strata = get_variable(physeq_joined_nonzero_mindepth, "sample"),
       permutations=999)
```

```
Call:
adonis(formula = ps_joined_mindepth_dist ~ maxEE.F + truncQ,      data = as(sample_data(physeq_joined_nonzero_mindepth), "data.frame"),      permutations = 999, strata = get_variable(physeq_joined_nonzero_mindepth,          "sample")) 

Blocks:  strata 
Permutation: free
Number of permutations: 999

Terms added sequentially (first to last)

            Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)    
maxEE.F      1      0.05 0.04930 0.10245 0.00009  0.324    
truncQ       1      0.35 0.34803 0.72328 0.00064  0.001 ***
Residuals 1124    540.85 0.48119         0.99927           
Total     1126    541.25                 1.00000           
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

Even after removing outlier samples, `truncQ` still has a significant (but small) effect on community composition, whereas `maxEE` has no effect. Between-sample variation is still much greater than between-parameter-set variation.


# Plot outputs of DADA algorithm, separating sequencing runs

```{r}
# Load data from test_dada2_params.R for separated runs
prop_Fs_mapped_to_asv <- readRDS( "./data/sensitivity_prop_Fs_mapped_seprun.Rds")
# dadaFs_list <- readRDS("./data/sensitivity_dadaFs_list_seprun.Rds")
# dadaRs_list <- readRDS("./data/sensitivity_dadaRs_list_seprun.Rds")
seqtabs <- readRDS("./data/sensitivity_seqtabs_list_seprun.Rds")
# taxas <- readRDS("./data/sensitivity_taxas.Rds")
n_merged <- readRDS("./data/sensitivity_n_merged_seprun.Rds")
prop_merged <- readRDS("./data/sensitivity_prop_merged_seprun.Rds")

dada_out_seprun <- list()
for(j in 1:length(prop_merged)) {
  paramset_index <- unlist(lapply(seq_along(prop_merged[[j]]), function(i) { rep(i, length(prop_merged[[j]][[i]]))}))
  dada_out_seprun[[j]] <-
    data.frame(
      runID = runIDs[[j]],
      maxEE = params[paramset_index, 1],
      truncQ = params[paramset_index, 3],
      prop.Fs.mapped = unlist(prop_Fs_mapped_to_asv[[j]]),
      prop.merged = unlist(prop_merged[[j]])
    )
}
```

Plot the proportion of forward reads that were assigned to an ASV in the DADA denoising algorithm (out of the reads which have been filtered and dereplicated):

```{r}
dada_out_seprun[[1]] %>%
  ggplot(aes(x=factor(maxEE), y=prop.Fs.mapped, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_mapped1
dada_out_seprun[[2]] %>%
  ggplot(aes(x=factor(maxEE), y=prop.Fs.mapped, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_mapped2
gridExtra::grid.arrange(p_mapped1, p_mapped2, nrow=2)
```

Plot the proportion of unique ASVs that successfully merged (out of the unique ASVs that have been denoised):

```{r}
dada_out_seprun[[1]] %>%
  ggplot(aes(x=factor(maxEE), y=prop.merged, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_merged1
dada_out_seprun[[2]] %>%
  ggplot(aes(x=factor(maxEE), y=prop.merged, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_merged2
gridExtra::grid.arrange(p_merged1, p_merged2)
```


# Plot effects on diversity estimates, separating sequencing runs

For now, we don't have taxa tables yet. 

```{r}
physeqs_seprun <- list(list(),list()) # List of two lists: each sub-list is a different sequencing run
for(j in 1:length(runIDs)) {
  for(i in 1:length(seqtabs[[j]])) {
    physeqs_seprun[[j]][[i]] <- phyloseq(otu_table(seqtabs[[j]][[i]],taxa_are_rows=FALSE))
  }
}

obsrich_list_seprun <- list(list(), list())
shannon_list_seprun <- list(list(), list())
for(j in 1:length(runIDs)) {
  for(i in 1:length(physeqs_seprun[[j]])) {
    div <- suppressWarnings(
      estimate_richness(physeqs_seprun[[j]][[i]], measures=c("Observed","Shannon"))
    )
    obsrich_list_seprun[[j]][[i]] <- div[,"Observed"]
    shannon_list_seprun[[j]][[i]] <- div[,"Shannon"]
  }
}

diversity_out_seprun <- list()
for(j in 1:length(runIDs)) {
  paramset_index <- unlist(lapply(seq_along(obsrich_list_seprun[[j]]), function(i) { rep(i, length(obsrich_list_seprun[[j]][[i]]))}))
diversity_out_seprun[[j]] <- 
  data.frame(
    runID = runIDs[j],
    maxEE = params[paramset_index, 1],
    truncQ = params[paramset_index, 3],
    obs.richness = unlist(obsrich_list_seprun[[j]]),
    shannon.div = unlist(shannon_list_seprun[[j]])
  )
}
```

Plot observed richness: 

(Note: DADA2 does not allow singletons, so this measure should not be used directly for ecological inference.)

```{r}
diversity_out_seprun[[1]] %>%
  ggplot(aes(x=factor(maxEE), y=obs.richness, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_obsrich1
diversity_out_seprun[[2]] %>%
  ggplot(aes(x=factor(maxEE), y=obs.richness, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_obsrich2
gridExtra::grid.arrange(p_obsrich1, p_obsrich2)
```

Plot Shannon diversity:

```{r}
diversity_out_seprun[[1]] %>%
  ggplot(aes(x=factor(maxEE), y=shannon.div, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_shannon1
diversity_out_seprun[[2]] %>%
  ggplot(aes(x=factor(maxEE), y=shannon.div, fill=factor(truncQ))) +
  geom_boxplot() +
  facet_grid(runID~.) ->
  p_shannon2
gridExtra::grid.arrange(p_shannon1, p_shannon2)
```

Compare with plots where sequencing runs were processed together:

```{r}
gridExtra::grid.arrange(p_obsrich, 
                        gridExtra::grid.arrange(p_obsrich1, p_obsrich2, nrow=2), nrow=1)
```

```{r}
gridExtra::grid.arrange(p_shannon, 
                        gridExtra::grid.arrange(p_shannon1, p_shannon2, nrow=2), nrow=1)
```

Any differences between pooled-run and seperated-run processes must be very small. Confirm with ANOVA:

```{r}
diversity_out$seperate_seq_runs <- FALSE
diversity_out_seprun[[1]]$seperate_seq_runs <- TRUE
diversity_out_seprun[[2]]$seperate_seq_runs <- TRUE

diversity_test_sep <- rbind(diversity_out, diversity_out_seprun[[1]], diversity_out_seprun[[2]])
diversity_test_sep_obsrich <- aov(obs.richness ~ maxEE + truncQ + runID + seperate_seq_runs + 
                                    seperate_seq_runs:truncQ + seperate_seq_runs:maxEE, 
                              data = diversity_test_sep)
summary(diversity_test_sep_obsrich)
```

```{r}
diversity_test_sep_shannon <- aov(shannon.div ~ maxEE + truncQ + runID + seperate_seq_runs + 
                                    seperate_seq_runs:truncQ + seperate_seq_runs:maxEE, 
                              data = diversity_test_sep)
summary(diversity_test_sep_shannon)
```

Confirmed: In the case of performing inference on alpha diversity, it does not matter whether you pool the runs together in the DADA algorithm or run the DADA algorithm on the runs separately.
