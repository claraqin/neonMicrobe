
---
title: "Sensitivity Analysis for Quality Filtering Parameters"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{sensitivity-analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_knit$set(
  root.dir = "~/zhulab/neonSoilMicrobeProcessing/" # Update as necessary. Should refer to the absolute filepath of the project root directory (e.g. .../neonSoilMicrobeProcessing)
)
```

## Note for editors: Need to update section on beta-diversity by adding an environmental gradient to compare against parameter effects

The purpose of this vignette is to demonstrate how a researcher can test the effects of various DADA2 quality filtering parameter combinations on the outputs of the DADA2 pipeline, and ultimately, on the ecological inference. Specifically, this vignette asks the following from a subset of NEON 16S marker gene sequences:

* What are the effects of quality filtering parameters on the number of remaining reads?
* What are the effects of quality filtering parameters on alpha and beta diversity metrics?

The parameters that we vary to observe their downstream effects include the following:

* `trunLen.R`: Reverse reads that do not meet or exceed `truncLen.R` in length will be discarded. Reverse reads that exceed `truncLen.R` will be truncated to `truncLen.R`.
* `maxEE.R`: After truncation, reads with greater than `maxEE` expected errors will be discarded. Expected errors are calculated from the nominal definition of the quality score: EE = sum(10^(-Q/10)).

Because we are interested in variation in these benchmark metrics across different parameter sets, we refer to this analysis as a **sensitivity analysis**. This vignette is intended to provide a boilerplate for users of this R package to construct their own sensitivity analyses.

**Note:** If you are using this vignette as a reference, rather than running it as an RMarkdown script, be aware that you will need to manually set the working directory to the project root directory, e.g. `setwd(".../neonSoilMicrobeProcessing")`.

# Dependencies

To begin, ensure that you have installed all dependencies.

Load libraries:

```{r message=FALSE}
library(dada2)
library(ShortRead)
library(Biostrings)
library(tibble)
library(dplyr)
library(vegan)
library(phyloseq)
library(ggplot2)
library(tidyr)
```

In addition, source files associated with this package:

```{r}
source("./R/utils.R")
source("./code/params.R")
```

## Constants used for this sensitivity analysis:

Quality filter parameters that we do not vary in this sensitivity analysis

```{r}
MAX_EE_FWD <- 8
TRUNC_LEN_FWD <- 240
MIN_LEN <- 50
```

Parameters specific to this sensitivity analysis

```{r}
N_SAMPLES <- 200
DIRNAME_TEST <- "qf_test_2-8-2021"
runIDs <-  c("runB69PP", "runB69RN", "runB9994", "runBDNB6", "runBF462", "runBFDG8", "runBNMJ5", "runBNMWB", "runBRPH4", "runC24VW", "runC25T6", "runC5B2R", "runC7WK3", "runC8VMV", "runC977L", "runC983L", "runCBJYB", "runCBTWG", "runCDHG2", "runCDJ5J")
```

Parameter value grid. The following allows testing of two quality filtering parameters at a time.

```{r}
PARAM1 <- "maxEE.R"
PARAM2 <- "truncLen.R"
grid <- expand.grid(c(4, 8, 16), c(170, 220, 250))
params <- matrix(
  c(grid[,1],     # PARAM1
    grid[,2]),    # PARAM2
  byrow=FALSE, ncol=2,
  dimnames = list(NULL, c(PARAM1, PARAM2))
)
param_sets <- apply(params, 1, function(x) paste(c(rbind(c(PARAM1, PARAM2), x)), collapse="_"))
```

# Assign filepath variables

```{r}
if(is.null(PRESET_OUTDIR_SEQUENCE) | PRESET_OUTDIR_SEQUENCE == "") {
  PATH_16S <- file.path(PRESET_OUTDIR, "raw_sequence", "16S")
} else {
  PATH_16S <- file.path(PRESET_OUTDIR, PRESET_OUTDIR_SEQUENCE, "16S")
}
PATH_RAW <- file.path(PATH_16S, "0_raw")
PATH_TRIMMED <- file.path(PATH_16S, "1_trimmed")
PATH_TEST <- file.path(PATH_16S, DIRNAME_TEST)
dir.create(file.path(PATH_TEST, "results"), recursive=TRUE)
```

## Get fastq files for this analysis

Retrieve files that match the sequence run IDs specified earlier.

```{r}
rawFs <- sort(list.files(PATH_RAW, pattern = paste0("(",paste0("(", runIDs, ")", collapse="|"),")", ".*_R1\\.fastq"), full.names = TRUE))
rawRs <- sort(list.files(PATH_RAW, pattern = paste0("(",paste0("(", runIDs, ")", collapse="|"),")", ".*_R2\\.fastq"), full.names = TRUE))
```


Retrieve metadata. If you saved your metadata to file, you can load it here:

```{r}
meta0 <- read.csv("./NEON/sequence_metadata/mmg_soilMetadata_16S_2021-01-12135435.csv")
meta <- qcMetadata(meta0, PATH_TEST, pairedReads="N", rmDupes=TRUE, rmFlagged="Y")
```

If you did not save your metadata to file, you can re-download it using `downloadSequenceMetadata()`:

```{r eval=FALSE}
meta <- downloadSequenceMetadata(targetGene = "16S")
```

Remove any samples that only have forward reads or only have reverse reads.

```{r}
matched_fn <- removeUnpairedFastqFiles(rawFs, rawRs, meta)
rawFs <- matched_fn[[1]]
rawRs <- matched_fn[[2]]
```

To cut down on computation time, select up to N_SAMPLES samples from the runs, up to N_SAMPLES/length(runIDs) from each run.

```{r}
if(length(rawFs) > N_SAMPLES) {
  rawFs_subset <- c()
  rawRs_subset <- c()
  for(i in 1:length(runIDs)) {
    rawFs_runID <- rawFs[grep(runIDs[i], rawFs)]
    rawRs_runID <- rawRs[grep(runIDs[i], rawRs)]
    if(length(rawFs_runID) > N_SAMPLES/length(runIDs)) {
      set.seed(101010+i)
      subset <- sample(seq(1,length(rawFs_runID)), N_SAMPLES/length(runIDs), FALSE)
      rawFs_subset <- c(rawFs_subset, rawFs_runID[subset])
      rawRs_subset <- c(rawRs_subset, rawRs_runID[subset])
    } else {
      rawFs_subset <- c(rawFs_subset, rawFs_runID)
      rawRs_subset <- c(rawRs_subset, rawRs_runID)
    }
  }
  rawFs <- rawFs_subset
  rawRs <- rawRs_subset
}
write.csv(cbind(rawFs, rawRs), file.path(PATH_TEST, "input_files.csv"))
```

Ensure there are no poor quality flags or legacy data in the subset.

```{r}
# meta_ext <- matchFastqToMetadata(c(rawFs, rawRs), meta)
meta_ext <- matchFastqToMetadata(c(rawFs_subset, rawRs_subset), meta)
with(meta_ext, table(sequencerRunID, qaqcStatus.dna))
with(meta_ext, table(sequencerRunID, qaqcStatus.pcr))
with(meta_ext, table(sequencerRunID, qaqcStatus.seq))
with(meta_ext, table(sequencerRunID, dataQF.rawFiles))
with(meta_ext, table(sequencerRunID, dataQF.dna))
with(meta_ext, table(sequencerRunID, dataQF.pcr))
with(meta_ext, table(sequencerRunID, dataQF.seq))
```

Plot quality profiles

```{r fig.show="hold", out.width="25%"}
profiles_list <- list()
for(i in 1:length(runIDs)) {
  # Retrieve only those files associated with the appropriate runID
  profiles_list[[i]] <- gridExtra::grid.arrange(
    plotQualityProfile(grep(runIDs[i], rawFs, value=TRUE), aggregate=TRUE),
    plotQualityProfile(grep(runIDs[i], rawRs, value=TRUE), aggregate=TRUE),
    ncol=2,
    top=runIDs[i]
  )
}
for(i in 1:length(profiles_list)) {
  plot(profiles_list[[i]])
}
```


Split complete filenames into "basenames" and directory names

```{r}
fn_base <- basename(c(rawFs, rawRs))
PATH_PARAMSETS <- file.path(PATH_TEST, param_sets)
```


## Trim primers from sequences

Trim reads based on the primer sequences supplied in `params.R`.

```{r, eval=FALSE}
trim_trackReads <- trimPrimers16S(fn_base, PATH_RAW, PATH_TRIMMED, "CCTACGGGNBGCASCAG", "GACTACNVGGGTATCTAATCC")
```

## Run quality filter on sequences

To store the results arising from each set of parameter choices, we construct a list object where each element corresponds to the output given a different parameter set. For this step, the list object is `filter_trackReads`.

```{r, eval=FALSE}
filter_trackReads <- list()
for(i in 1:length(param_sets)) {
  filter_trackReads[[i]] <- qualityFilter16S(
    fn_base,
    PATH_TRIMMED,
    PATH_PARAMSETS[[i]],
    maxEE=c(MAX_EE_FWD, params[i,1]), # Vary maxEE.R
    truncLen=c(TRUNC_LEN_FWD, params[i,2]), # Vary truncLen.R
    minLen=MIN_LEN,
    multithread=MULTITHREAD)
  rownames(filter_trackReads[[i]]) <- paste0(param_sets[i], "|", rownames(filter_trackReads[[i]]))
}
filter_trackReads_mat <- do.call(rbind, filter_trackReads)
```

Optionally, save the read-tracking table, in case the job fails:

```{r, eval=FALSE}
write.csv(filter_trackReads_mat, file.path(PATH_TEST, "results",  "sensitivity_trackReads_filter.csv"), row.names=TRUE)
```

## Run the rest of the processing pipeline

Although the quality filtering step is the only part of the processing pipeline where we vary the parameters, we must follow through with the rest of the pipeline to observe the downstream effects on remaining reads, merging rate, taxonomic resolution, and alpha- and beta-diversity estimates.

This requires us to redefine the list structure so that it becomes nested: in the first level, each element corresponds to a parameter set; in the second level, each element corresponds to a sequencing run ID. This is necessary because the dada sequence inference algorithm is sensitive to error rate estimates, and error rates may differ considerably between sequencing runs. Here we initialize the nested list structure for two types of outputs simultaneously.

```{r}
seqtabs <- dada_trackReads <- lapply(1:length(param_sets), function(x) lapply(1:length(runIDs), function(y) list()))
```

Now we continue with the processing pipeline to produce different versions of the resulting sequence tables.

```{r}
for(i in 1:length(param_sets)) {
  for(j in 1:length(runIDs)) {
    message("Sensitivity analysis: parameter set ", param_sets[i], ", sequencing run ",  runIDs[j])

    # Retrieve only those files associated with the appropriate parameter set and runID
    fn_base.star <- grep(runIDs[j], fn_base, value=TRUE)

    seqtab.list <- runDada16S(fn_base.star, PATH_PARAMSETS[i], MULTITHREAD, VERBOSE, seed=11001100)
    seqtabs[[i]][[j]] <- seqtab.list$seqtab.nochim
    dada_trackReads[[i]][[j]] <- seqtab.list$track

    rownames(seqtabs[[i]][[j]]) <- paste0(param_sets[i], "|", rownames(seqtabs[[i]][[j]]))
    rownames(dada_trackReads[[i]][[j]]) <- paste0(param_sets[i], "|", rownames(dada_trackReads[[i]][[j]]))
    
    # Can save work as you go:
    saveRDS(seqtab.list$seqtab.nochim, file.path(PATH_PARAMSETS[i], paste0("sensitivity_seqtab_", runIDs[j], ".Rds")))
    write.csv(seqtab.list$track, file.path(PATH_PARAMSETS[i], paste0("sensitivity_trackReads_dada_", runIDs[j], ".csv")), row.names=TRUE)
  }
}

dada_trackReads_mat <- do.call(rbind, lapply(dada_trackReads, function(x) do.call(rbind, x)))
```

Combine all read-tracking tables:

```{r}
trim_trackReads_mat <- do.call(rbind, lapply(1:length(param_sets), function(i) {
  rownames(trim_trackReads) <- paste0(param_sets[i], "|", rownames(trim_trackReads))
  trim_trackReads
}))

track <- Reduce(
  function(x, y, ...) transform(merge(x, y, by=0, all = TRUE, ...), row.names=Row.names, Row.names=NULL),
  list(trim_trackReads_mat[,1],
       filter_trackReads_mat,
       dada_trackReads_mat)
)
names(track) <- c("input", "trimmed", "filtered", colnames(dada_trackReads_mat))
track[is.na(track)] <- 0

```

Now that sequence inference is complete, we can join the sequencing runs back together in each parameter set:

```{r}
seqtabs_joinrun <- lapply(1:length(param_sets), function(x) list())
for(i in 1:length(param_sets)) {
  seqtabs_joinrun[[i]] <- mergeSequenceTables(tables = seqtabs[[i]])
}
```

Save the data so far:

```{r}
saveRDS(seqtabs_joinrun, file.path(PATH_TEST, "results", "sensitivity_seqtabs_joinrun_list.Rds"))
write.csv(track, file.path(PATH_TEST, "results", "sensitivity_trackReads.csv"), row.names=TRUE)
```

You can reload RDS objects into R to pick up where you left off:

```{r, eval=FALSE}
seqtabs_joinrun <- readRDS(file.path(PATH_16S, "qf_test_1-13-2021", "results", "sensitivity_seqtabs_joinrun_list.Rds"))
track <- read.csv(file.path(PATH_16S, "qf_test_1-13-2021", "results", "sensitivity_trackReads.csv"), row.names=1)
```


## Sensitivity of read counts

We can now plot the number of reads remaining after each step in the processing pipeline.

First, add parameter information to the read tracking table. This custom function simply parses the parameter sets from the rownames of the tracking table.

```{r}
track <- parseParamsFromRownames(track, PARAM1, PARAM2)
```

Next, perform a few more operations to make the tracking table ready for plotting:

```{r}
# Reshape read tracking table
track_long <- tidyr::gather(track, key = "step", value = "reads", input:nonchim)
# Exclude metrics associated only with forward reads
track_long <- track_long[!grepl("F$", track_long$step),]
# Aggregate read counts by run ID
track_long[["step"]] <- factor(track_long[["step"]], levels=colnames(track)[1:9])
track_aggRun <- group_by(track_long, maxEE.R, truncLen.R, runID, step) %>%
  dplyr::summarise(reads = sum(reads))
```

Plot!

```{r, fig.width=9, fig.height=3.5}
theme_set(theme_bw())
ggplot(track_aggRun, aes(x=step, y=reads, col=as.factor(maxEE.R))) +
  geom_line(aes(linetype=as.factor(truncLen.R), group=interaction(maxEE.R, truncLen.R))) +
  # facet_wrap(~runID, scales="free_y") +
  facet_wrap(~runID) +
  labs(linetype="truncLen.R", color="maxEE.R") +
  scale_linetype_manual(values=c("dotted", "dashed", "solid")) +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  scale_y_continuous(trans="log10")
ggsave(file.path(PATH_TEST, "results", "track_reads_plot.png"), width=10, height=7, units="in")
```


## Sensitivity of alpha diversity

First, we convert the sequence tables into phyloseq objects.

```{r}
physeqs <- list() # Create a list of physeq objects
for(i in 1:length(param_sets)) {
  # Sample data (parameters)
  sampledata <- parseParamsFromRownames(seqtabs_joinrun[[i]], PARAM1, PARAM2, keep_rownames=TRUE, keep_original_cols = FALSE)
  physeqs[[i]] <- phyloseq(otu_table(seqtabs_joinrun[[i]], taxa_are_rows=FALSE),
                           sample_data(sampledata))
}
```

We make use of `phyloseq`'s `estimate_richness()` function. 

```{r}
obsrich_list <- shannon_list <- list()
for(i in 1:length(physeqs)) {
  div <- suppressWarnings(
    estimate_richness(physeqs[[i]], measures=c("Observed","Shannon"), split=TRUE)
  )
  obsrich_list[[i]] <- div[,1]
  shannon_list[[i]] <- div[,2]
}

diversity_list <- lapply(seq_along(physeqs), function(i) { 
  parseParamsFromRownames(
    cbind(
      sample_data(physeqs[[i]]), 
      obsrich = obsrich_list[[i]], 
      shannon = shannon_list[[i]]
    ),
    PARAM1, PARAM2
  )
})

diversity_df <- do.call(rbind, diversity_list)
```

Plot!

```{r, fig.width=5, fig.height=5}
theme_set(theme_bw())
ggplot(diversity_df, aes(y=obsrich, col=as.factor(truncLen.R), x=as.factor(maxEE.R))) +
  geom_boxplot() +
  # facet_wrap(~runID, scales="free_y") +
  facet_wrap(~runID) +
  labs(col="truncLen.R", x="maxEE.R") +
  ylab("Observed richness")
ggsave(file.path(PATH_TEST, "results", "diversity_plot_obsrich.png"), width=10, height=7, units="in")
```

```{r, fig.width=5, fig.height=5}
theme_set(theme_bw())
ggplot(diversity_df, aes(y=shannon, col=as.factor(truncLen.R), x=as.factor(maxEE.R))) +
  geom_boxplot() +
  # facet_wrap(~runID, scales="free_y") +
  facet_wrap(~runID) +
  labs(col="truncLen.R", x="maxEE.R") +
  ylab("Shannon index")
ggsave(file.path(PATH_TEST, "results", "diversity_plot_shannon.png"), width=10, height=7, units="in")
```

Test statistical significance using ANOVA

```{r}
obsrich_aov <- aov(log(obsrich) ~ truncLen.R + maxEE.R + runID + truncLen.R:runID + maxEE.R:runID, data=diversity_df)

png(file.path(PATH_TEST, "results", "aov_diagnostics_obsrich.png"))
par(mfrow=c(2,2))
plot(obsrich_aov)
dev.off()
```


```{r}
options(knitr.kable.NA = '')
knitr::kable(summary(obsrich_aov)[[1]], digits=3)
```


```{r}
shannon_aov <- aov(shannon ~ truncLen.R + maxEE.R + runID + truncLen.R:runID + maxEE.R:runID, data=diversity_df)

png(file.path(PATH_TEST, "results", "aov_diagnostics_shannon.png"))
par(mfrow=c(2,2))
plot(shannon_aov)
dev.off()
```

```{r}
options(knitr.kable.NA = '')
knitr::kable(summary(shannon_aov)[[1]], digits=3)
```

**In conclusion,** `truncLen.R` affects alpha-diversity inference, whereas `maxEE.R` does not (within the range of `maxEE.R` values that we tested). `truncLen.R` affects alpha-diversity inference to a different degree depending on the sequence run. 


## Sensitivity of beta diversity

First, combine all sequence tables into ONE large sequence table. A sample data table will distinguish samples processed using different parameters.

```{r}
seqtab_joined <- mergeSequenceTables(tables=seqtabs_joinrun)

# Sample data (parameters)
sampledata <- parseParamsFromRownames(seqtab_joined, PARAM1, PARAM2, keep_rownames=TRUE, keep_original_cols = FALSE)
```

**FOR TESTING ONLY**: Custom function to match rownames in this sequence table (which are based on the original fastq filenames) to the sequence metadata.

```{r}
matchSeqtabToMetadata <- function(tab, meta, verbose=TRUE) {
  rownms <- rownames(tab)
  samplenms <- sub(".*\\|", "", rownms)
  
  # Remove runID if appended to beginning of filename
  key <- sub("^run[A-Za-z0-9]*_", "", samplenms)
  
  # Append "_R1" to end of samplenames
  key <- paste0(key, "_R1.fastq.gz")

  # # Append ".gz" to end of filename if missing
  # key[!grepl(".gz$", key)] <- paste0(key[!grepl(".gz$", key)], ".gz")

  key_match <- match(key, as.character(meta$rawDataFileName))
  if(any(is.na(key_match))) {
    if(verbose) {
      message("Matching file names to metadata: ", sum(is.na(key_match)), " files did not have matching records in the provided metadata. ",
              "Double-check to ensure that the provided metadata is of the appropriate scope.")
    }
  }
  return(cbind(rowname = rownms, meta[key_match,], stringsAsFactors=FALSE))
}

meta_seqtab <- matchSeqtabToMetadata(seqtab_joined, read.csv("./NEON/sequence_metadata/mmg_soilMetadata_16S_2021-01-12135435.csv"))
sampledata_with_meta <- cbind(sampledata, meta_seqtab)
all(rownames(sampledata_with_meta) == meta_seqtab$rowname)
```

```{r}
meta_seqtab %>%
  group_by(dnaSampleID, siteID, plotID, collectDate) %>%
  dplyr::summarise(n=n(), .groups="drop") %>%
  dplyr::select(-n) ->
  meta_seqtab_summary
meta_seqtab_summary
```

Combine sequence table and sample data table into a phyloseq object:

```{r}
physeq_joined <- phyloseq(otu_table(seqtab_joined,taxa_are_rows=FALSE),
                          sample_data(sampledata_with_meta))
```

Remove samples with zero total counts

```{r}
physeq_joined_nonzero <- prune_samples(sample_sums(physeq_joined) > 0, physeq_joined)
```

Optionally, discard taxa with 10 or fewer reads:

```{r}
physeq_joined_nonzero <- prune_taxa(taxa_sums(physeq_joined) > 10, physeq_joined)
```

Ordinate, one sequencing run at a time. (Samples from different sequencing runs may be highly dissimilar, producing difficult-to-interpret ordination plots.)

```{r, message=FALSE}
ord_list <- ps_runID <- list()

for (i in 1:length(runIDs)) {
  ps_runID[[i]] <- subset_samples(physeq_joined_nonzero, runID==runIDs[i])
  set.seed(1010101)
  ord_list[[i]] <- ordinate(ps_runID[[i]], "NMDS", "bray", k=2)
  saveRDS(ord_list[[i]], file.path(PATH_TEST, "results", paste0("sensitivity_ordination_", runIDs[i], ".Rds")))
}
```

Load ordination data if previously run:

```{r}
for(i in 1:length(runIDs)) {
  ord_list[[i]] <- readRDS(file.path(PATH_TEST, "results", paste0("sensitivity_ordination_", runIDs[i], ".Rds")))
}
```

Plot the ordinations!

Generalize to plot with one facet for each runID:

```{r}
stress_annotations <- lapply(ord_list, function(o) {
  data.frame(xloc=Inf, yloc=-Inf, 
             label=paste0("Stress: ", formatC(signif(o$stress,digits=3), digits=3,format="fg", flag="#")),
             hjust=1.10, vjust=-0.10)
})

theme_set(theme_bw())
ordplot_list <- list()
for(i in 1:length(ord_list)) {
  sampledata <- as(sample_data(ps_runID[[i]]), "data.frame")
  sampledata$maxEE.R <- as.factor(sampledata$maxEE.R)
  sampledata$truncLen.R <- as.factor(sampledata$truncLen.R)
  sampledata <- cbind(sampledata, scores(ord_list[[i]])[match(rownames(sampledata), rownames(scores(ord_list[[i]]))),])
  ordplot_list[[i]] <- ggplot(sampledata, aes(x=NMDS1, y=NMDS2)) +
    geom_point(aes(col=truncLen.R, shape=maxEE.R)) + 
    stat_ellipse(aes(group=sampleID), lwd=0.1, col="grey20") +
    scale_shape_manual(values=c(21, 22, 24)) +
    guides(col=FALSE, shape=FALSE) +
    ggtitle(runIDs[i]) +
    geom_text(data=stress_annotations[[i]], aes(x=xloc, y=yloc, label=label, hjust=hjust, vjust=vjust), size=3) +
    NULL
}
g <- gridExtra::arrangeGrob(grobs=ordplot_list, ncol=5)
ggsave(file.path(PATH_TEST, "results", "ordination_plot.png"), plot=g, width=10, height=7, units="in")
plot(g)
```

Try ordinating ALL sensitivity analysis samples:

```{r}
# Start by pruning low-sequencing depth samples and removing uncommon taxa
ps_nonzero_mindepth <- prune_samples(sample_sums(physeq_joined_nonzero) > 2500, physeq_joined_nonzero)
ps_nonzero_mindepth <- prune_taxa(taxa_sums(ps_nonzero_mindepth) > 15, ps_nonzero_mindepth)
set.seed(1010101)
ord_all <- ordinate(ps_nonzero_mindepth, "NMDS", "bray", k=2)
saveRDS(ord_all, file.path(PATH_TEST, "results", paste0("sensitivity_ordination_all_runs.Rds")))
```


```{r, fig.width=12}
sampledata <- as(sample_data(ps_nonzero_mindepth), "data.frame")
sampledata$maxEE.R <- as.factor(sampledata$maxEE.R)
sampledata$truncLen.R <- as.factor(sampledata$truncLen.R)
sampledata <- cbind(sampledata, scores(ord_all)[match(rownames(sampledata), rownames(scores(ord_all))),])
sampledata$collectYear <- as.integer(format(as.Date(sampledata$collectDate), "%Y"))
sampledata$processedYear.rawFiles <- as.integer(format(as.Date(sampledata$processedDate.rawFiles), "%Y"))
sampledata$processedYear.dna <- as.integer(format(as.Date(sampledata$processedDate.dna), "%Y"))
sampledata$processedYear.pcr <- as.integer(format(as.Date(sampledata$processedDate.pcr), "%Y"))
sampledata$processedYear.seq <- as.integer(format(as.Date(sampledata$processedDate.seq), "%Y"))
```

At this point I noticed there were two clusters in the ordination, and chose to filter the ordination dataset to only look at one set of quality filtering parameters, so it was clear that the clusters were not produced by the parameters.

```{r}
sampledata_selectparams <- sampledata[sampledata$maxEE.R==4 & sampledata$truncLen.R==220,]
gridExtra::grid.arrange(
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=processedYear.rawFiles)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=processedYear.dna)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=processedYear.pcr)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=processedYear.seq)) + stat_ellipse(aes(group=processedYear.seq))
)
```

```{r}
cor(sampledata$NMDS1, sampledata$processedYear.seq)
```

```{r}
n_distinct <- apply(sampledata, 2, function(x) length(unique(x)))
n_distinct[n_distinct <= 3]
```

```{r, fig.width=12}
gridExtra::grid.arrange(
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=library_strategy)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=library_source)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=library_layout)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=sequenceAnalysisType)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=testProtocolVersion.pcr)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=testProtocolVersion.seq))
)
  
```

```{r, fig.height=8, fig.width=6}
gridExtra::grid.arrange(
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=siteID)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + geom_point(aes(col=domainID))
)
gridExtra::grid.arrange(
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + stat_ellipse(aes(group=siteID), lwd=0.5, col="grey") + geom_point(aes(col=siteID)),
  ggplot(sampledata_selectparams, aes(x=NMDS1, y=NMDS2)) + stat_ellipse(aes(group=domainID), lwd=0.5, col="grey") + geom_point(aes(col=domainID))
)
```

```{r}
n_distinct[grep("rotocol", names(n_distinct))]
```

Weird -- there is a separation in the ordination that maps to *the year in which sequencing was performed.* Even though I don't think this is an artefact from our pipeline, I still think that it may be prudent to select only one of the sequencing years in order to avoid confusion, at least until we can confirm the source of this artefact.

```{r}
sample_data(ps_nonzero_mindepth)$processedYear.seq <- as.integer(format(as.Date(get_variable(ps_nonzero_mindepth, "processedDate.seq")), "%Y"))
ps_seq2019 <- subset_samples(ps_nonzero_mindepth, processedYear.seq %in% c(2017, 2018))
set.seed(1010101)
ord_all <- ordinate(ps_nonzero_mindepth, "NMDS", "bray", k=2)
saveRDS(ord_all, file.path(PATH_TEST, "results", paste0("sensitivity_ordination_seq2017-18.Rds")))
```



Test statistical significance using permANOVA. 

First run permANOVA using all three levels of `truncLen.R`.

```{r}
ps_joined_dist <- vegdist(otu_table(physeq_joined_nonzero_runC5B2R))
```

```{r}
adonis(ps_joined_dist ~ maxEE.R + truncLen.R,
       data = as(sample_data(physeq_joined_nonzero_runC5B2R), "data.frame"),
       strata = get_variable(physeq_joined_nonzero_runC5B2R, "sampleID"),
       permutations=999)
```

Also, use betadisper to ensure homogeneity of within-group variances (dispersion). Heterogeneity of within-group variances may be confounded with distances between groups in the permANOVA test.

```{r}
beta_disper <- vegan::betadisper(ps_joined_dist, get_variable(physeq_joined_nonzero_runC5B2R, "truncLen.R"))
anova(beta_disper)
```

```{r}
mod.HSD <- TukeyHSD(beta_disper)
plot(mod.HSD)
```

Next re-run permANOVA using only top two levels of `truncLen.R`.

```{r}
ps_joined_dist_hitrunc <- vegdist(otu_table(physeq_joined_nonzero_runC5B2R_hitrunc))
```

```{r}
adonis(ps_joined_dist_hitrunc ~ maxEE.R + truncLen.R,
       data = as(sample_data(physeq_joined_nonzero_runC5B2R_hitrunc), "data.frame"),
       strata = get_variable(physeq_joined_nonzero_runC5B2R_hitrunc, "sampleID"),
       permutations=999)
```

Also, use betadisper to ensure homogeneity of within-group variances (dispersion). Heterogeneity of within-group variances may be confounded with distances between groups in the permANOVA test.

```{r}
beta_disper_hitrunc <- vegan::betadisper(ps_joined_dist_hitrunc, get_variable(physeq_joined_nonzero_runC5B2R_hitrunc, "truncLen.R"))
anova(beta_disper_hitrunc)
```

```{r}
mod.HSD_hitrunc <- TukeyHSD(beta_disper_hitrunc)
plot(mod.HSD_hitrunc)
```

**In conclusion,** both `truncLen.R` and `maxEE.R` affect beta-diversity inference, though to different extents. `truncLen.R` affects mean community composition and within-group variance (dispersion) in a non-linear fashion, with drastically different results for the lowest level of `truncLen.R` tested (`truncLen.R == 160`); This is probably due to the large drop-off in read volume at the merging step due to insufficient read overlap. When ANOVA is constrained to only the higher two levels of `truncLen.R`, both `truncLen.R` and `maxEE.R` are found to be significant in determining mean community composition, but with very small effect sizes.
